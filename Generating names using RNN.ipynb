{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssthedarklord/IntroToDL/blob/master/Generating%20names%20using%20RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nMKNYovIXCw",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "320v60vNIXCz",
        "colab_type": "code",
        "outputId": "d921134c-0c66-41d6-b6dc-bb16ca90841d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-10-24 12:54:01--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3595 (3.5K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-24 12:54:02 (46.5 MB/s) - ‘setup_google_colab.py’ saved [3595/3595]\n",
            "\n",
            "1.12.0-rc1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmBPj5ncIXC3",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "HYnat96oIXC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "# pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "HcxVCjUyIXC7",
        "colab_type": "code",
        "outputId": "8826496e-f6b9-4f0f-cec8-cddedd11111a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "-u-7nYWvIXC8",
        "colab_type": "code",
        "outputId": "160ca444-45c4-40ec-b04b-b8776b348584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdf4a994240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcUHgXVIXDA",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "1ExyErOBIXDA",
        "colab_type": "code",
        "outputId": "ca53f93b-b7d8-4ade-ab8c-14ffddc0f376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens = set(''.join(names))### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byv_7d5qIXDD",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "fFrkO9C3IXDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {c: i for i, c in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "eF1MdscLIXDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "M2RAyFvpIXDK",
        "colab_type": "code",
        "outputId": "7ce6cf63-48e6-4eb7-b082-c6fe27d47f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 5 46 52  2 24  2  7 44  0]\n",
            " [ 5 48 44 12  6 17  0  0  0]\n",
            " [ 5  8  6 27 20 20 27  7  0]\n",
            " [ 5 48 27 12 47  2 11 11  7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adY1MDJ7IXDN",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "7TfXf4X1IXDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "buuU_w2gIXDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0PsTy8lIXDT",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "65fIEwGCIXDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyOX244zIXDY",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "TB2ikzUZIXDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBld-htoIXDb",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "Q_ZYIxOfIXDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vnTxl7RIXDe",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "Gps425VcIXDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*tf.log(tf.clip_by_value(predictions_matrix,1e-10,1.0)), reduction_indices=[1]))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zg3k5-iIXDi",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "cZ7IrFTGIXDj",
        "colab_type": "code",
        "outputId": "ec109e93-3dcc-4219-a84d-0f0c648b4acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xdg1PX9+PHnjQxCBgHCDBAh8GZP\nQXEBYgFX1Tq/otbxra3barXTqrW/arVuqlSr9WttreIeOOoCRBABQYa8mQHCTMgggYxbvz9u5C43\nk1wI9/m8Hn/lPp/Pfe79ziWve9/rvSwejwchhBCpy9rRBRBCCNE2EsiFECLFSSAXQogUJ4FcCCFS\nnARyIYRIcfYj/YJlZTWtHiaTn59FZeXhZBbnqCd1Ngepszm0pc4FBTmWaOdSqkVut9s6ughHnNTZ\nHKTO5tBedU6pQC6EECKcBHIhhEhxEsiFECLFSSAXQogUJ4FcCCFSXELDD5VSnYC1wH1a6xeCjp8G\n/AlwAfO11ve1RyGFEEJEl2iL/HdARYTjTwDnAycCM5RSw5NVMCGEEImJG8iVUkOB4cD7zY4PBCq0\n1ju11m5gPjC9XUoJVBys58X566mtc7TXSwghREpKpEX+MHBbhOO9gLKgx/uB3skoVCRbdh9k3qeb\nePqttbjc7vZ6GSGEaJH5899lzpzHOrQMMXPkSqkrgCVa621KqXj3ijp9NFh+flarZjfN6pbNio3l\nLFu/lw+/KeXKs0a0+B6pqqAgp6OLcMRJnc3BCHXOyckkKys94bq0R53jdXaeCQxUSp0FFAINSqlS\nrfUnwG68rXK/vr5jMbVlbYXbZ4/nxoc+440vNqP65lFcmNfqe6WKgoIcyspqOroYR5TU2RyMUuea\nmnoOH27kr399hk8//RiAk0+ewmWXXcmyZUt59tmnyMjIJD+/K08++Rgff/xFyLG77/4jdnv8cSex\nPgBiPltrfbH/Z6XUPUCJL4ijtS5RSuUqpYqAUuAsYHbc0rRBVmYal81QPPrqat5bUsKtF45pz5cT\nQqSQVz/bzDcb9if1nhOH9uCiU4vjXrdnzy5WrFjGs8++CMC11/6YadNO4/XXX+HGG3/OmDHjWLDg\nM6qqqsKOVVdX0a1b9zaVs8XjyJVSVyqlzvM9vA54GVgEvKK13tim0iRg1MBuFBfm8d2WA5TsPdje\nLyeEEHFt3LiRESNGYbfbsdvtjBo1hs2bNzJt2mk89ND9vPji8wwerCgoKAg71tYgDi1YxlZrfU+E\nYwuByW0uRQudfUIRj766mkWr91DUK/dIv7wQ4ih00anFCbWe24PFAsEb2TscDiwWK7Nmnclxx01m\n4cIv+OUvf85f/zon7Ngf//ggAwYUten1U3Jm5/CifDLTbazfXtnRRRFCCIYMUaxduwan04nT6WT9\n+nUMGaJ44YW/Y7PZOeecHzF9+gy2bNkSdqykZGubX/+IbyyRDDarleLCPNZuraC6toG87IyOLpIQ\nwsR69erDuHHHctNN1+J2ezj77HPo1as3PXv24tZbrycnJ5ecnBxuvPFn7N17IOTYJZdc1ubXtwR/\nHTgS2rJDUHAv9/tLSnh9wVZ+ds4IJg3rmaziHXWM0rPfElJnc5A6t/i5xtghKJjqlw/Axp1VHVwS\nIYToWCkbyIt655But6IlkAshTC5lA7ndZmVQ3zx2lR2S9VeEEKaWsoEcoKiXd6bT7vJDHVwSIYTo\nOCkdyAu6dAKgrKqug0sihBAdJ6UDefcumQAcqK7v4JIIIUTHSelAnu8bP15V29DBJRFCiI6T0oG8\nS44/kDd2cEmEEKLjpHQgz8qwk2a3UiktciGEiaV0ILdYLHTJTpfUihDC1FI6kAN0yc7g4KFG3O4j\nu9SAEEIcLQwRyD0eOHhY8uRCCHMyRCAHGbkihDCv1A/kOekAVNVIi1wIYU4pH8hzs7yBXFIrQgiz\nSvlAnpnu3RujvtHVwSURQoiOYYBAbgOgodHZwSURQoiOkfKBPMMXyOsd0iIXQphTygfyzDR/i1wC\nuRDCnFI+kGekSyAXQpibYQK5pFaEEGZlj3eBUioLeAHoCWQC92mt3ws6XwLsBPyRdLbWeleyCxqN\npFaEEGYXN5ADZwPLtdYPKqUGAP8F3mt2zela69qkly4BaXYrFou0yIUQ5hU3kGutXwl62A8obb/i\ntJzFYiEz3SYtciGEaSXSIgdAKfUVUAicFeH0XKVUEfAl8GutddSlCPPzs7DbbS0tZ0BBQU7YsU4Z\naThdnojnjMCo9YpF6mwOUufkSDiQa61PUEqNBV5SSo0JCta/Bz4EKoC3gPOB16Ldp7LycKsLW1CQ\nQ1lZTdjxNLuVQ/WOiOdSXbQ6G5nU2Rykzi1/bjRxR60opSYopfoBaK1X4Q3+Bf7zWusXtdb7tdZO\nYD4wqlWlbIPMNBsNkiMXQphUIsMPTwFuB1BK9QSygXLf4zyl1EdKqXTftVOAte1R0Fgy0qw0NLrw\neGRzCSGE+SQSyOcCPZRSi4D3gRuAK5RS52mtq/G2wpcqpRYDZcRIq7SXNN8QRKfLfaRfWgghOlwi\no1bqgEtjnH8ceDyZhWqpdLv386jR6SatDR2pQgiRilJ+Zid4OzsBGh3SIhdCmI+hArlDUitCCBMy\nRCBP96VTHDJyRQhhQoYI5GlBOXIhhDAbQwVyhwRyIYQJGSKQp0sgF0KYmCECuX/IYaNTcuRCCPMx\nSCCXFrkQwrwMEcgltSKEMDNDBPK0NBm1IoQwL0MEchlHLoQwM0MEchlHLoQwM0MEcsmRCyHMzBCB\n3D/8UAK5EMKMDBHIm5axlRy5EMJ8DBHIZRy5EMLMDBHIbTYLAE6XbPUmhDAfQwTyNJu3Gi63tMiF\nEOZjiEBus0lqRQhhXoYI5HZfasXlltSKEMJ8DBLIvdVwylZvQggTMkQgt1l9nZ2SWhFCmJAhArnF\nYsFus+CU1IoQwoTs8S5QSmUBLwA9gUzgPq31e0HnTwP+BLiA+Vrr+9qnqLHZbVZJrQghTCmRFvnZ\nwHKt9RTgIuCRZuefAM4HTgRmKKWGJ7eIibHbrLhkHLkQwoTitsi11q8EPewHlPofKKUGAhVa652+\nx/OB6cD6JJczLpvNgkNa5EIIE4obyP2UUl8BhcBZQYd7AWVBj/cDg2LdJz8/C7tvkavWKCjIiXg8\nI82GJ8b5VGbEOsUjdTYHqXNyJBzItdYnKKXGAi8ppcZorSPlMSzx7lNZebgl5QtRUJBDWVlNxHMW\ni4WGBmfU86kqVp2NSupsDlLnlj83mrg5cqXUBKVUPwCt9Sq8wb/Ad3o33la5X1/fsSPObrNIZ6cQ\nwpQS6ew8BbgdQCnVE8gGygG01iVArlKqSCllx5t2+bh9ihqb3WqVRbOEEKaUSCCfC/RQSi0C3gdu\nAK5QSp3nO38d8DKwCHhFa72xXUoah90uLXIhhDklMmqlDrg0xvmFwORkFqo17FYrLrcHj8eDxRI3\nVS+EEIZhiJmd0LRwlqRXhBBmY5hAbpOFs4QQJmWYQN60uYS0yIUQ5mKYQO7f7k02lxBCmI1hArl/\nTXKXpFaEECZjuEAuS9kKIczGQIHcP2pFWuRCCHMxUCCXUStCCHMyTCC3yThyIYRJGSeQ+/btdEuO\nXAhhMoYJ5FaLBHIhhDkZJpD7W+QyIUgIYTaGCeRWCeRCCJMyTCC3Wb1VkdSKEMJsDBTIpUUuhDAn\nwwRyf2rF7ZFALoQwF8ME8qYWuUwIEkKYi2ECeaCzUyYECSFMxjCBXCYECSHMynCB3CU5ciGEyRgm\nkFulRS6EMCnDBHIZfiiEMCvDBHJpkQshzMowgVxa5EIIs7IncpFS6kHgZN/192ut3wg6VwLsBFy+\nQ7O11ruSW8z4ZK0VIYRZxQ3kSqlpwEit9WSlVDfgW+CNZpedrrWubY8CJkrWWhFCmFUiqZWFwIW+\nn6uAzkopW/sVqXUktSKEMKu4LXKttQs45Ht4DTDfdyzYXKVUEfAl8GutddRomp+fhd3e+s+BgoKc\niMcPHHIAkJmZFvWaVGW0+iRC6mwOUufkSChHDqCUOgdvIJ/R7NTvgQ+BCuAt4HzgtWj3qaw83PJS\n+hQU5FBWVhPx3MGDdQDU1jZEvSYVxaqzUUmdzUHq3PLnRpNoZ+dM4LfALK11dfA5rfWLQdfNB0YR\nI5C3F/9Wb5JaEUKYTdwcuVIqD3gIOEtrXdH8nFLqI6VUuu/QFGBt8osZn6x+KIQwq0Ra5BcD3YFX\nlVL+Y58Ba7TWb/pa4UuVUnV4R7Qc8dY4yIQgIYR5JdLZ+QzwTIzzjwOPJ7NQrWGzSWpFCGFOxpnZ\naZEWuRDCnAwTyK2yjK0QwqQME8hlYwkhhFkZJpDLVm9CCLMyTCCXKfpCCLMyUCD3LZolOXIhhMkY\nJpDLMrZCCLMyTCCXzk4hhFkZJpD7hpFLi1wIYToGCuQWbFaLrLUihDAdwwRy8ObJJbUihDAbQwVy\nb4tcArkQwlwkkAshRIozViC3WXHKzE4hhMkYKpDbbRacTunsFEKYi8ECuRWnjFoRQpiMoQJ5ms0q\nLXIhhOkYKpDbJUcuhDAhYwVyuwWnS1rkQghzMVYgt1pxuT2yAqIQwlSMFcjt3uq4pFUuhDARQwXy\nNJu3Og6ntMiFEOZhqEBut3mXQJQ8uRDCTOyJXKSUehA42Xf9/VrrN4LOnQb8CXAB87XW97VHQRNh\n97XIJZALIcwkbotcKTUNGKm1ngzMAh5rdskTwPnAicAMpdTwpJcyQf5A7pBALoQwkURSKwuBC30/\nVwGdlVI2AKXUQKBCa71Ta+0G5gPT26WkCfB3dspYciGEmcRNrWitXcAh38Nr8KZPXL7HvYCyoMv3\nA4Ni3S8/Pwu73daKonoVFOREPZebnQFATk5mzOtSjZHqkiipszlInZMjoRw5gFLqHLyBfEaMyyzx\n7lNZeTjRlwxTUJBDWVlN1POORicAZeW15Ga0/sPiaBKvzkYkdTYHqXPLnxtNop2dM4HfArO01tVB\np3bjbZX79fUd6xA26ewUQphQIp2decBDwFla64rgc1rrEiBXKVWklLIDZwEft0dBE5EWGH4oOXIh\nhHkk0iK/GOgOvKqU8h/7DFijtX4TuA542Xf8Fa31xqSXMkH+zs7gUSt7DhzirUXbmD1jCLlZ6R1V\nNCGEaDeJdHY+AzwT4/xCYHIyC9VagXHkQUvZPv3WWkrLDpHdKY3LZ6qQ62vrHByqd9AzP+uIllMI\nIZLJYDM7w3Pk9Y3eATZ1vo7QYLfN+ZJf/20pbtnnUwiRwgwWyL058uDUir8DNFKw9ufSZcNmIUQq\nM1Qg9y+a5Qrq7LRZvcE9VrCWZW+FEKnMWIHc19nZ6MuRL/t+H7vLvXOZYqVPJLUihEhlhgrkOb5R\nKQcPNQIw9+11gXPSIhdCGJWhAnl+jneKfmVNfdi5WIFccuRCiFRmqEDeJdsfyBvCzsVKn3gkkAsh\nUpihAnma3UpOVhqVtY1h56RFLoQwKkMFcoD87AyqahrwNMt7S2enEMKoDBfIu+Rk0OBwBSYC+bnc\n0RfSks5OIUQqM1wgz8r0rjpwqN4Rctzl9nC43skny3dS32yWp6RWhBCpLOH1yFNFpwxvlR59dXXI\ncZfbw8ufbmTxmr3sr6rj0tOGBM5JakUIkcqM1yL3BfI9B0I3sHC7PYFjYeckjgshUpjhAvneisg7\nELncHqy+6frNW+D//u9G3vlyW7uXTQgh2oPhAvnxw3tGPF7X4GRzqXdzo+aBXO+s4i0J5EKIFGW4\nQD5+SEHE4zWHmzo/9c4qqg+FjzVvrrbOwfIN+8OGMgohxNHEcIHcYom7/zMAD/xrZdxr5rz+HU+9\ntZbluqytxRJCiHZjuECeqH1RcunBNvpSMfsr41/rt6usloOH47f2hRAiWUwbyFviuy0HErrO4XRz\n13PLuH3O4nYukRBCNJFAnoBNpdVs31sT9zqHbx10mWAkhDiSDBnIo3V4tkXFwfClcZuTqf5CiI5g\nyED+k7OHM6BnTouft2pTeSAYB2/gDJBIiHa5oq/nIoQQ7cVwU/QBMtJsDCvKZ/u++OmQYE+8/h0/\nOLYfowZ15ZFXQqf4JzIE0emSFrkQ4shLKJArpUYCbwOPaq3nNDtXAuwE/MsNztZa70piGY+oz1aW\nciBCGuWvb67l+V+disfjiTrE0RljhUUhhGgvcQO5Uqoz8CTwaYzLTtda1yatVMnQysaxy+2JOs3/\nkVdW0eBwcc5Jx/DYvO/4zeXjKeqV6305j4eqCDsTCSFEe0skR94AnAHsbueyHDV2lx+KeHzttgo2\nlVbzl/+swuly8+7iksC5lz7eyJ///e0RKqEQQjSJ2yLXWjsBp1Iq1mVzlVJFwJfAr7XWHZ4s9rS2\nSd4C9Y0uPlq2g89X7mJ/VV3Iudo6Bzv21TC8qGtC93pr0VZWbizjnqsmBRb3SkRtnYOq2gYKC7Jb\nVHYhhHEko7Pz98CHQAXwFnA+8Fq0i/Pzs7Dbba1+sYKCxEajnH7iQD5atrPVr5MIN/Dq55uJ1A/6\n4MvfUrq/lsdvm0qvblk8+vJKzj91MEMHRA7s7/ha9xlZGXTJyQg5F6vOt9z1ATWHG3n5j2eQ3Smt\ntVU56iT6PhuJ1Nkc2qPObQ7kWusX/T8rpeYDo4gRyCtbMN29uYKCHMrKEhuJkpth49k7p/KTB78I\nO/eX60/gF0991epy+NUebowYxAFK93u7DLbvqmTxt6UsXbuX5d/v45k7psW8Z/mBWhz1TVP849W5\nxrccQOmuKrrlZbawBkenlrzPRiF1Noe21DnWB0CbxpErpfKUUh8ppdJ9h6YAa9tyz2SyWZuq95vL\nJgR+ttuTM3y+odm+oJFkpttx+MaXJzI80eVys3X3wcAs0UQluFaYEMKA4kY0pdQEpdQXwJXALUqp\nL5RStymlztNaVwPzgaVKqcVAGTFa4x3h9ovHculpgykuzAscswB3XzkRgKJeOTx03Qmtunfw0rjR\nuN0egpvtL32sA5OOPl1Rypbd1SHXf7hsB398cTn//Ei3qCwyqVQI80qks3MFMDXG+ceBx5NYpqQa\ncUxXRhwTmpe2WCwM6JXDr2aPp1tuZqtTEg2O+C1yl8vNt5vKA48/W7mLMcXdGdAzh3/9dyMAz//q\n1MD5T5aXArBswz6uPnNYwmVxSSQXwrQMOUU/mrt+fCw/nqUCnYJD+nWJGsSf/9WpdMoI7ZS1tWA0\niZ/T7aGk2YJblTUNYUsANJfouup+sjyAEOZlqkB+TO9cpoztm/D1d/zPuJDHd/342Ba/5ldr94Yd\na2h0UVrWNH/qmXfWhV1j9QXyRHcnar59nRDCPEwVyBMxelA3jvPt+9kpoynzNHVcX/p079zi+329\nfl/YscMNTh6b913g8dII1/jz6Hc+uYjH5q0OO9/cXc8ti3jc4/EERrYIIYzJkItmtcYfrp7EzrJa\nJo/oFTiWFRTIr5iporaOzznpGN5uwebNiVzrcHhTJRu2VyZ8X7fbE5hMtHpzOcs37KdbXibvLC7h\n9ovHhvUV+O3cX8u6bRXMnNSvxSmd9rCv4jB4PIFvJUKI2CSQ+xT2yKawR+jsyOAWOUTPW/frkfxZ\nlc3XNv9uywFGD+rGv/+7kW55mcyc1D/sOQ0OF2VVdZRX1zPnjTUh5x5+ZRV3XzmRAb3Cx6Le/by3\nNT90QJfA2jGJirWIWGus2lzOE699x+nH9+fCqcVJu68QRiaplRjstvBfz/TxhSGPVb8ujB9SwNkn\nFCX99Z99d33g57lvr8Xt9vDJilJe+WwztXUOvttSHnJ9o9PNPf/4JiyI+/35394Np/dX1VFeXRd2\nvvm4+OpDjTE7ZXeXH+L6RxeydF14P0Aitu+tobYudAjnGt+2eotW72nVPdvKJStYihQkgTwBwSmW\n2TOGhJw768QiwJteicZmtURsCcezJChA1je6Qh7f/PiikDw7xB8OWe8L1L+au4Q7n16Cy+3mcH3k\nsfD7q+r4+ZNf8vz730e937ptFTQ0ungm6AMnUZU1Ddz7wjf87tmlIcf96at4A4S+/G4Pn64obfHr\nxvLB19v5yYNfsCvKomlHk0aHix0tXG9fGJcE8jjm3j6FR286KeTYjIn9yM/J4O4rJzLCtyhWrIWu\nHr3pJLo2Wz+lNZ6LEVQB6uqdce+xL2iJhL0Vddz42KLA4617DrJmq7dFvGlnFeDtiK1rcPLB0u00\n+ILH5ytLOXiokUXfJd5qLquqY/mG/YHHt//Vu0H1wWaTqvwpJUucSP78/O8D4/Dj2bGvJqGgN+/z\nLQCs2lSW0H3Bu5NUtA/D9rJ9bw0/e3gB9/zjG7buPnhEX1scnSRHHkd6WvgCX5dMH8wl0wdHvD4/\nJ4Nxg7tjt1n5+JudDO3fhexOaeQ3C+QThhSwr7KOa384nH//dyMbdlS1uayvLdgS95pf/62pBVzX\nEBr4/YHs73dOC5m1+ti81WwqrcZms/KfTzcFXquuoekbQG2dgzmvf8cFU4tDZtH6/e7vX+NwuvnT\ntcfTo0unqOXzj6JMtKNz3hebw3Lpm3dV0+hwBVaevOcf3wChE6+S5f6XVrBtTw3P3DE1YiquPTz6\n6qrAz7vKahnYJ36/hsPp4ttN5Ywt7h7xbzqWZPeDiOSTQJ5Ec2+fgtVqwW6z4vF4GDognxFF+QBh\ngfzkMb0ZPag7ALmd00PODSnMY2Np6NT9RJTsaVnrrL4hcgu+4mA9DmdTkN7kK0vwv3JwEAdYuHo3\nG0ur+dNLK7j36kkAfLNhH8V981i6fl9g7Zjq2gbeX1IS8tw9Bw6xubSak8f0weOL5JHixtL1e3l/\nyfaQdXM+WLojLJD/6Z8rAPjbL6Zy13NfB47HCkgLV8dfbj/S87ft8bb0D9U7yWv2PraX+uC+jATj\n65uLtvHh1zuYNak/F52aeCey0+XmpscXccLIXlw+I+ZS1qIDSSBPouCWjsViYWxx98DjLtmhgTw/\np2lGaVqzllznVi5HW5/AIl7BKmsj72hUVlWHI8ICX9EWG7NY4LUvmr4N3P38MixE3qSp0elm8ZrQ\nztHfPusNtoP65sVskT/zjjcXv7pZJ280ew4cYn9lU6fu7vJD1DW6KO4b+o2hvtHJCx9sCKpP+GtX\nHKznF099xSXTBzNjYj8qDtaHLL2wubSaCaogoXK1VfCIJksCkdzt8fDh1zsAWryPbW2dg4ZGF5+v\n3JWygfyfH2myMu2cP2VQRxel3UiO/AgZU9ydY4f2ILdzOvk5GRQWNE0uOvfkgQwOSkc4XR6uP3dk\n4PF5J0fvSA3mauHszhc/jLww15dr9tIYoeO0siZ8L1OIvGBXtJLEmpzU4HAFNgSJlVppdEQeWeLx\neGKuSHnXc8v40z9XhI1Mab4qZaT5At/5+g78qaUH/rUyJEf/1zfXcPUDn/H5t+Hb1VYfamTlxtC8\neyIrZ0YT/D4nkvEIHlV0pNI/LV29sz19/u0u3l+yvd1fx+32sHN/bdjQ4SNBAvkRkt0pjevPHclj\nN53EX64/IaTV1y0vk19fNiEwc7R7XiZpQa3fs2IMbUxrw5K80QL/knV7+fib8E05kvHPUFYV+cMA\nvKN76n0pm/1VdTz15hrKq+q48+mveD0o/384Sqfuk6+v4bpHFgQeR6vfU2+uZcGqXRyud+DxeJi/\nNLRery/YyrPvhi6bEBwvl67bS3l15Hr88yPtndAU5M//WsmcN9awqdTbD7J9bw3XPbIg0EoGWL2p\njBseXcCeA/FHzATHiWiB/HC9M/BhXLKnqRVut3mfUNfgpLwqfAiqX83hRm54dAGfrQz/YPJ4PDGX\nhNixr4af/uULPlq2I+o1HeHdr0ra/f53P78soTRdskkg7wDR8rTXnDmMkQO7cu7Jx4RcY7FYuHxm\n5K+1d/7POG780ah2KWdzyWhoNA9ywcqr61m1uSldsVyXcefcJZRX14d8iFQ1Swn5Hwc/F6L3AXy7\nqZz/+1Dzy7lLuObPn4cEVL8l60KXTQh+P95ctDVqHQD0ztCOa/9m3gd8wd8f0F/9fHPgmide+Za6\nBhfv+YKN2+0JGWEE3lb86806tKOlVm58bCG3zVkcVvZvN5Xzwdfb+c2zS7lz7hIefmVVyPNq6xw8\n//73fL5yV0h5gj308rfc+NjCsONut4fH563m8de8w2L9nedtcfBwY8z1hjaVVgV+r/G8uXArlb4N\n0kvLavm2BaOTErHse+/fzPptFUm9byIkkB9Fjumdy20XjSUnKz2spZUeoeX92E0nMahvHuOHFPCT\ns4eTk5XG+VMGxn2dvM7pDO3fJVnFbpFI68r4RZvI1Fzzbwu3zVnMz5/8Muy6w1ECud+hOMM1/a3O\ndxZv4zvfRCWAvM6xh5IeqK7nvv/7hnUlFezc37Q4mj8cRRo14s/l+xu6r36+mV//bal3rL7DhdPl\n5v2lJRG/FX3x7S52lR+its7BPz/WgfSVv/7N/5bmfb6F6lrvNeu2VYR0bL/3VQlfrtnDWzGWkdiw\noyqsP6aypoHSslpWbzkQCJbBQ3KXfb+PtxZtDdnbNt46QFt2V3PrE1+GLGnhcrsDgb22zsH9L63k\nzqebdvtqaHTxp5dW8K0vldU8zeEfKvr755bx5OtrQia8RZpk1xJ7Dng/eCOlr0r31wZ+L+1BOjuP\nUs3/GHp3C1+wK3i0y+QRvZg8ohe1dQ5eXxC9xXjPVRPp3zOHFXp/UoY8xjKwT+4RG+dcfSg8IDRf\nPrilPv5mJ1PG9uGtRaFBLV4O9OPlO2lodPHwf0Jbu8++u57OmWlhE7eCx6Ev37Cf+gYnq30fHAtW\n7eLhV1YxuDCPbrnhSy6XltfywVLvN4oRx3Rl3bYKDgXNlp33xWa+CRq/H8nP/rKA53xDMyP1jfgd\nqK4PWfbZ7VsPZ9ueg9z3f8vDrvdv0OXxeJj7tjdV9eWaPfzl+hMB+OcH3zPv00389vIJDOobPmRV\n+/4+31lcQmFBNvWNLp6f/z2jB3Xj1gvHBN5zD94PiolDe7Bi4342l1bzZOkanv/VqWHLO5dV14f0\niTicbtaXVKL6d+HxeavZsvsgd1wylmEJbpredJ+m35vNFvrJ2ehw8fvnl5GRZuO1B85q0X0TJYH8\nKKX6deGkUb2Z6cuPJzJWGLxxSL3RAAARtklEQVS5+KduO4VXP9/CFxE63vr3zAlcF8nxI3qydF30\nVnOi8nMyAt8ienbNiplSaS9tzel/sWpXSPrDL96HU6yOzMfmreaHvtnA4F1Dp0/3rMBjl9sTCOLg\nTS+Bdwho7pDw4Y2rgkbO+IefBn8T8Qf5WDw0Da2MtQ3i219uC9nsZPWmct5YtJVdZZHz+o0Ob+s5\nuNVbcdDbKnW53czzdRyv3lLOoL55LF6zh0anm2nj+lJZ0xBIVQA89VbTDpL+b0fBH1hz315H97xO\nBPdjO5yusI7sp95cG1KeGx71pohOP64/W3zv6+4Dh6MG8re/3IbL7Wb6hH6s31bBO1+VcOLIXpw4\nqnfgmuaNMH9qLZGNaFpLAvlRymq1cPWZw1q1WWtmuj0wk7S4bx6bd4WPSY80xDErw84VM1UgkF91\n+lBK9tZEHInhl9c5PWJruHNmWqCzsVN6yyagHC2Chy4mU2lQ4Hts3mqO6Z3Yh/SKjeE5Xf/XeWhK\nFe0pb/mH5oHqetZvr8RujR7IHc1at08mkArbsa+W7l3Cv0kEf8g6nd6/E//M5Wnj+vKfTzexY19t\n2PP83B5P2FaL+yoPh+TTb37iS04KCrBA1LWDgmf+RrvmcL0zkOZ576um8r+xcCujBnYLPG7+O2yv\nv6NgkiNPIb27eVtuZxw/gAd+enzMa38wsR/nnnwM1507kosjTADJDAquPbt673vS6N5kpjd9thcX\n5nH5TMXN54+O+jq/nD0+4vGMdCuFBd5VIZuP247nlovHMbwoP6SMRtJ8KOK2Fk7kiufAwcQ6/4I9\n/MoqXvhgQ8wRFy63J+GNTvwenbeaqtrwD/rgDsEPl+0IGcdfXdvA7jijd178cEPY0ghlVXUhw14b\nGl0Jr8ezrqRpuejmgXxXWS2H6h3UxliKIbhj2maz8M7ibdzx1Fc0NLpC1u5p6e8vUdIiTyF3Xjqe\njTurOFYVxJ0ynZFm44cnesefz5zUn8kje4VMPOqWm8mUsX0YXtSVY1UB2/bUUORb2Otn54xg1eby\nQIDv2TXylPrpEwrp1TUr6J4ZHPB9dU6327hg6iAKe2RzwohefNKCBa6cLje/uGQcby3ayjuLSwLH\nxw3uHjIJJxkumDqItVsPtHt/wdFun6/VGKuDePmG/Xw1qFvU85EcPNTIu4tD+xg27qwKm7kc/AHy\nc99om1gWrt4TaCj4vb1oGxdHWTqjJRxON4tW7+bg4UamjO3LXc8tIz8ngxvOiz46zN8HALB4zZ7A\nt6Pg4bAA/122g3EDW5Z/T4S0yFNIXud0Jg7t0ap1L3Kz0kPWV7dYLPx41tDA/Qb2yQ2MMpg0rCfX\nnj0iMCknI8raHH19k5p+NXs81587kjOOHxA4l2a30inDzrRxfclIt3H1GYlvJO1vaR2reoQcv2LW\n0KCfE5tlmJ+Twf9E+efuW9CZGRP7BZZKSMTxvt2jzCrewm2RNF9N8oF/rUxKWf79yaaQxx6aJmy1\nxdY9B/nHBxt4fcFWbn7cu6hcZU0DS9cntlxzrNFQS9a0z/LM0iIXcXXNzeSWC0bTr0c2L3+yiR75\nnSguzAssQTCkn3co44JVTbn05kPsJqgCnp/vDQK3XTSGR15t2r5u7u1TONzg5LOVpXy+chdTxhfi\nbnRS2CObZ++cSqPDTV2Dk9ysprz+1LF9GV7UlV/NXRK13EP7d2H2D4bQu1tnXg76Bx/avwtji7sz\nw7c5x8xJ/Zi/dDu1dQ6OHdojZJXG5i4+tTjmEMpE5XZO52CEvoX2MLa4O8cOLeDv7yUehPNzMpI2\nXC5aZ+jRau3WyOPAP1ne9mWT22vtMWmRi4SMKe5O19xMbvjRKC6cVsy4weHpnZ75TWmW8YNDW7md\nMuxcOG0Qd1wylpEDu/HUbacEzqXZrXTJzuBHpwziyVtPoVteUyrHZvW27LvmZgYmRt164RgA8rJC\nR3Fc1myt+KvPGEbfgmysQevB33DeKO68dHwgiIP328l910xi1nH9ufqMoSH3CB7i+fANJ5KXnRF4\n/dayWS2cOj7+JuDxNvu+KcGJYMMG5DNyYMtSIvdePSlk20NxdJMWuUiaoQPyueOSsYGfmzv9uKbU\nS2a6nd9cPoHKmoYWpYqmjWsKgGlpoe2Q5sO+ugctl3v3lRNj3jcvO4OLpoV2Ct/4o1EMLszjzYVb\nOXNyUWAFy9FBeeK/3zmNu/+xjL0HDjNqYDcqaurDRlvccsHowGxHgD/+5DgKunTi7UXbAp1z/zND\nMXZgVxocLn7v20g7J87iaX0K4m8GPmNiP6YfWxhzSr3flLF9GDWwG0P7dyErM43/PWsY32zYFzKE\nb9Zx/Vm4anfcyVat8fRtU7j/pRXs2B99tEqqS2SRs9ZIqEWulBqplNqilLoxwrnTlFLLlFJLlFJ3\nJb+IIpUMK+rKsKKuCQXn4r55TBzaI+510VgtFn556bjA4+DZr3/wLaXbGqcf15/sTmmMHtSNnKx0\nrpg1NGQiTEgZrBbuvXoST98+hZsvGM25J4fPrFXNZtH2zM/CarFwvK/Fe/GpxVw6cygFXTqFdOBl\nZ6Xx9O1TmP2Dpm8av/B9UELonrKTR4Tm7v3zDmZO6o/V4l1a+Q9XT+L2S8YGOrGby81KZ/yQArIy\nvR8gFoslUJ8zJw/g2TunctG04sB6LelpscOHf+0gv6uafdu5bNZQrjlzGA/8bDKP33wSGek27r4q\n9AN38oienH58f/7fT45jxsR+EV9n3OD4fRzHxliZ8tofDo/7/EjOO/mYkPdmWITGS3PttaBW3Ba5\nUqoz8CTwaZRLngBmAruABUqp17XWLd/7S4hWCF4eeHhRV2xWC1PG9gnbSLslLpxWzIXTYq/Z/dMf\njggMU7NaLFht4R9c9/3vcew9cJjMdDu3XzI2bKbn7B8MZtSgrhw3LDQIP3rTSVTW1AeGgk6fUEhx\n3zwaHK6QIZ3ZmU0t9uDVIqeM7cOlpw2hurYhZB38wh7ZFOKd3XvbnC/D1pRvvi4+ePsPjumdy+DC\nPGy+8dH+Fnrvrp0jLov7yI0n4vF4hwP6Ozbv/+nxFOR1ol+PbBas2u3tu+iVFzZHIrgB8JvLJoRs\nUnL+lIFhyzP075HNdeeO5MGXv2VzhDX8Rw/qhtPl5vrzRnH1A58BcPLo3uzcX0vJ3hpGHtOV3l3j\nf7MBOHFUL75evx+ny82kYT042zcqzL8K5mnHFvL99spYt2g3iaRWGoAzgF82P6GUGghUaK13+h7P\nB6YDEsjFEdGzaxZXnzGMgX1yye2czpyfn9KmFSETdVyU0Sv9fIH2WFVA3+6d6etrlY4o6srlM4Yw\noFfT5J+szDSOHx6eh87rnB62SUXwnq+P33wSWZl2rFYLXXMzqDjYEEjRZHdK48e+0T3do+zElJFm\n4zeXH8vLn2zkyllDudPXYRxp9rDNag1rafbs2olte2o4dmgBWZl2Rg/qxiufNc2A9X+4+kc7zTqu\nf6D/pKhXLkWzEpsAVZAfWv40e/joqXt837xuuWA0N/m2LRxcmBfYDCW4P2PyiF4sWbeXIf26kJFu\no2RvDcOLusacrzByYNdA5+c1Zw7npFG9mfvOOs6aXBR2bfPhkMHOnzKQD7/ewRntsEk7gCXRAepK\nqXuAcq31nKBjJwB3aK3P8z2+Bhiktf5NtPs4nS6PPcIbIoRRVNc2kJOVHnMf12RZv+0Ac+at4rdX\nHUdWhp3MDHtIyiURW3dVs3FHJTOPH5BQSqysso5Plm3n/FMHB0YnVdU0cPk9HwLw7sPnBK51uz0t\n/j18sWIn67dVcN35o8PKc/btbwd+HtArhzl3eNeI8Xg8/PAX7zBqUHfuvXYyP/rlu2FlqW90sn5b\nBeOGFOB0uVm9qZwJQ3tQXlXP1X/8OGJZXrp3Fv94bx1XnTWCvOzIi6X5y/TOX37IvorD/OvDDXyx\nsmmEyw8m9efmi8dFfG4LRf1FJruzM+47VlnZ+jU3WjNdPdVJnVPTgbqWDS1sbZ0LstO596pJgAdn\ng4PaBgct7SrMSbcyobgb5eWJP/O08X2prmr6Xw7e/zXRekSr84j+XRjRv0vE8txywWg276pmaP98\ninqHPv9vv5iK3WahqvIQd185kcwMW9j9+3XtFLjvgO5ZgZ/PO2UgQwrzWLh6d8gSxo11jcyePpjG\nukbKorynV50xlEaHm/LyWmzAD08YQMnu6sCibfX1jkA52vK3XVCQE/VcWwP5biD4u2Ff3zEhhInE\n6/hMljHF3RlTHLlzMzilFpyKSsTZvpTH4MIuTB3Xl/tfSnzS0smj+4Q87pKdwe+vnMhTb65huS4L\n6/RtD20K5FrrEqVUrlKqCCgFzgJmJ6NgQojUYbNaOW1CIf16tr6T+WhgtVoo7pvHaRMKGT+kbXuw\nXnn6MMYUd4/an5JMiYxamQA8DBQBDqXUBcA7wDat9ZvAdcDLvstf0VpvjHgjIYShXfqDIfEvSgEW\niyUpdcnKtIcsb9ue4gZyrfUKYGqM8wuByUkskxBCiBaQKfpCCJHiJJALIUSKk0AuhBApTgK5EEKk\nOAnkQgiR4iSQCyFEipNALoQQKS7hRbOEEEIcnaRFLoQQKU4CuRBCpDgJ5EIIkeIkkAshRIqTQC6E\nEClOArkQQqQ4CeRCCJHikr1nZ7tRSj0KHA94gFu01t90cJGSRin1IHAy3vfjfuAb4J+ADdgDXK61\nblBKzQZuBdzAM1rr5zqoyEmhlOoErAXuAz7F4HX21eVOwAn8HvgOA9dZKZUNvAjkAxnAvcBe4Gm8\n/8ffaa2v8117B3Ch7/i9Wuv5HVLoNlBKjQTeBh7VWs9RSvUjwfdXKZUGvAAMAFzAVVrrrYm+dkq0\nyJVSU4DBWuvJwDXAEx1cpKRRSk0DRvrqNgt4DPgD8Fet9cnAZuBqpVRnvP/8p+Hd6OPnSqmuHVPq\npPkdUOH72dB1Vkp1A+4GTsK7JeI5GLzOwJWA1lpPAy4AHsf7932L1vpEIE8pdbpS6hjgEpp+N48o\npWwdVOZW8b1vT+JtkPi15P29FKjSWp8E/D+8DbqEpUQgB6YDbwForb8H8pVSuR1bpKRZiLclAlAF\ndMb7Br/jO/Yu3jf9OOAbrXW11roOWAyceGSLmjxKqaHAcOB936GpGLvOpwGfaK1rtNZ7tNbXYvw6\nlwPdfD/n4/3QPibo27S/ztOAD7TWjVrrMmA73r+NVNIAnEHo5vNTSfz9nQ686bv2E1r4nqdKIO8F\nlAU9LvMdS3laa5fW+pDv4TXAfKCz1rrBd2w/0Jvw34H/eKp6GLgt6LHR61wEZCml3lFKLVJKTcfg\nddZa/wfor5TajLfB8gugMugSw9RZa+30BeZgLXl/A8e11m7Ao5RKT/T1UyWQN2fp6AIkm1LqHLyB\n/MZmp6LVNWV/B0qpK4AlWuttUS4xXJ3xlr0b8CO8KYd/EFofw9VZKXUZsENrXQycCrzU7BLD1TmG\nlta1Rb+DVAnkuwltgffB23lgCEqpmcBvgdO11tVAra8jEKAv3vo3/x34j6eiM4FzlFJLgf8F7sL4\ndd4HfOVruW0BaoAag9f5ROAjAK31aqAT0D3ovBHrHKwlf9OB476OT4vWujHRF0qVQP4x3s4SlFLj\ngd1a65qOLVJyKKXygIeAs7TW/o6/T4DzfT+fD3wIfA1MVEp18Y0GOBFYdKTLmwxa64u11hO11scD\nf8c7asXQdcb7N3yqUsrq6/jMxvh13ow3J4xSagDeD6/vlVIn+c7/CG+dPwPOVEqlK6X64A1u6zug\nvMnWkvf3Y5r6ys4GPm/JC6XMMrZKqQeAU/AO2bnB9wmf8pRS1wL3ABuDDv8Yb4DLxNvxc5XW2qGU\nugC4A+8QrSe11v86wsVNOqXUPUAJ3pbbixi4zkqpn+JNnwH8Ee8wU8PW2Reongd64h1aexfe4Yd/\nw9uI/FprfZvv2puA2Xjr/Dut9acRb3qUUkpNwNvvUwQ4gF146/MCCby/vlE6fwcG4+04vVJrvTPR\n10+ZQC6EECKyVEmtCCGEiEICuRBCpDgJ5EIIkeIkkAshRIqTQC6EEClOArkQQqQ4CeRCCJHi/j/c\nvo3MPHu8OAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdf41e40a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeBikUCrIXDn",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "8ii6A7GmIXDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "o7e1SgkTIXDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "3JKfdFd0IXDu",
        "colab_type": "code",
        "outputId": "3b0b5d89-5197-4b85-e134-4a27009fa8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " MlitemTTTTTTTTT\n",
            " OrymkaTTTTTTTTT\n",
            " BejaranTTTTTTTT\n",
            " DawTTTTTTTTTTTT\n",
            " PobpaedTTTTTTTT\n",
            " SurrenyTTTTTTTT\n",
            " SiesyTTTTTTTTTT\n",
            " HoundinkiTTTTTT\n",
            " DuciloTTTTTTTTT\n",
            " CaranTTTTTTTTTT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "cFSZu5CMIXDw",
        "colab_type": "code",
        "outputId": "530b6173-0878-4542-d706-9654c8e6a433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " TrumptyTTTTTTTT\n",
            " TrumpotTTTTTTTT\n",
            " TrumpTTTTTTTTTT\n",
            " TrumperTTTTTTTT\n",
            " TrumpeTTTTTTTTT\n",
            " TrumpyTTTTTTTTT\n",
            " TrumposTTTTTTTT\n",
            " TrumporaTTTTTTT\n",
            " TrumpetTTTTTTTT\n",
            " TrumpieTTTTTTTT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39NuOD5aIXDz",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "KcOXVsndIXD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"DOW2pXI548pY0dzz\"\n",
        "COURSERA_EMAIL = \"ssthechosenone@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "ZANCluvRIXD5",
        "colab_type": "code",
        "outputId": "7d064ae2-6913-447c-a668-6557c2ed36b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwe1k35bIXD8",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "l19YozesIXD8",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "N5WkCKXPIXD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dko90dQuIXED",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "SA-tybWBIXED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "5RDVf6pUIXEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}